{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to DSGBench","text":"<p>DSGBench is a benchmark designed to evaluate Large Language Models (LLMs) in dynamic game environments. It provides tools to assess an agent's decision-making, strategic planning, adaptability, and interaction capabilities in complex and diverse scenarios.</p>"},{"location":"#what-is-dsgbench","title":"What is DSGBench?","text":"<p>DSGBench focuses on testing the ability of LLM-based agents in the following aspects:</p> <ul> <li>Decision-making: Making optimal choices in real-time or turn-based game scenarios.</li> <li>Strategic Planning: Designing long-term strategies to achieve game objectives.</li> <li>Adaptability: Adjusting strategies dynamically in response to environmental changes.</li> <li>Multi-agent Interaction: Collaborating or competing with other agents in multi-agent games.</li> </ul> <p>By supporting games like Starcraft II, Diplomacy, Werewolf, and more, DSGBench provides a comprehensive benchmark for evaluating LLM performance in decision-making and interaction-heavy tasks.</p>"},{"location":"#key-features","title":"Key Features","text":"<ol> <li>Diverse Game Environments:    DSGBench includes a variety of game environments, each offering unique challenges to LLM agents:</li> <li>Real-time strategy: Starcraft II</li> <li>Turn-based strategy: Civilization</li> <li>Social reasoning: Werewolf</li> <li>Negotiation and diplomacy: Diplomacy</li> <li> <p>Strategic planning: Stratego</p> </li> <li> <p>Standardized Evaluation Metrics:    A set of well-defined metrics to evaluate agents across decision-making accuracy, adaptability, and strategic interaction.</p> </li> <li> <p>Extensible Framework:    Built on a modular codebase, DSGBench can be extended to support new games or integrate with other AI frameworks like OpenAI Gym.</p> </li> <li> <p>Open Source:    DSGBench is fully open-source, enabling researchers to contribute, customize, and extend its functionality.</p> </li> </ol>"},{"location":"#documentation-overview","title":"Documentation Overview","text":"<p>This documentation is divided into the following sections:</p> <ul> <li> <p>Environments:   Detailed descriptions of the supported games, including rules, challenges, and required agent capabilities.</p> </li> <li> <p>Evaluation and Capabilities:   Overview of the evaluation metrics and the specific skills needed to succeed in DSGBench environments.</p> </li> <li> <p>Code Framework:   Technical guide for setting up the environment, interacting with LLM agents, and running experiments.</p> </li> <li> <p>Experimental Setup:   Guide to setting up and running experiments, including dataset preparation and result analysis.</p> </li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>To get started with DSGBench, follow these steps:</p> <ol> <li> <p>Clone the Repository:    <code>bash    git clone https://github.com/your-repository/dsgbench.git    cd dsgbench</code></p> </li> <li> <p>Install Dependencies:    <code>bash    pip install -r requirements.txt</code></p> </li> </ol>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions to DSGBench! If you\u2019d like to report an issue, suggest a feature, or submit a pull request, please visit our GitHub repository.</p>"},{"location":"#license","title":"License","text":"<p>DSGBench is open-sourced under the MIT License - see the LICENSE file for details.</p>"},{"location":"#contact","title":"Contact","text":"<p>For any questions or feedback, please contact us at your-email@example.com.</p>"}]}